+++
title = "Safety Is an Illusion"
date = "2025-04-22T10:51:22-05:00"
#dateFormat = "2006-01-02" # This value can be configured for per-post date formatting
author = "Henry Post"
authorTwitter = "" #do not include @
cover = ""
tags = ["rant", "programming", "cybersecurity"]
# keywords = ["", ""]
description = ""
showFullContent = false
readingTime = false
hideComments = false
+++


What's the difference between "malware" and "software"?

In my opinion, it's the human who labels the code that. Code is merely a mechanism to modify data. It has no emotions, intent, "inherent evil-ness", etc. Do hammers enjoy being used to hammer nails?

A gun is an inert piece of metal. So is a screwdriver, or a hammer. You can use them to hunt for food and build a house, or to hurt other people. Are they "safe"? When are they not "safe"?

"AI Safety" is a massive, massive lie. "AI" is not the lie. "Safety" is! "safe" is a human invention.

Right now, I can purchase a $1,200 gaming laptop and go onto HuggingFace and download any Text2Text, Text2Img, Img2Img, Text2Vid, Vid2Vid, Text2Audio, etc - model that I want.

I can ask it to generate fake political videos. Maybe Joe Biden chasing cats through the white house! Maybe a fake video of someone doing something very evil. Maybe fake audio! Maybe some encryption ransomware. <http://github.com/meltingscales/owocryptor> (owocryptor was not written using AI.)

Tricking yourself into thinking that "AI safety" and "making a leadership council" and etc - will stop the wave of deepfakes and hacking that is a result of the democratization of knowledge that decentralized AI models such as those hosted on HuggingFace - is crazy. Just use HuggingFace and you'll see how local AI trumps all of those "safeguards".

I think that AI safety was dead the moment the NVIDIA Vid2Vid paper <https://github.com/NVIDIA/vid2vid> dropped, which was 7 years ago. AI safety is not going to ever work, because "safe code" simply does not exist outside of human conceptions of "safety". Cars are unsafe. Power tools are unsafe. Guns are unsafe. As long as a human can operate it, it can be deemed "unsafe". Heck, even having an algorithm operate a car can result in "unsafe" behavior, because "safety" is an entirely arbitrary and human-created concept. "Safety" does not exist.

So, long live AI safety! It was dead the moment that it was conceived. The true nature of this life is far more chaotic than any of us can imagine.

I really do think that "AI Safety" serves to pacify regulators, the general public, and allows companies to trick themselves into feeling safe.